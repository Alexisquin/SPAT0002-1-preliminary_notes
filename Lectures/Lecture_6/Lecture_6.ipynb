{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classical statistical inference: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Table of Content\n",
    "\n",
    "- III. [Maximum Likelihood (MLE)](#III)\n",
    "    - III.1 Likelihood function\n",
    "    - III.2 Maximum Likelihood estimation  \n",
    "    - III.3 Properties of MLE estimators\n",
    "- IV. Regression and Model fitting \n",
    "    - IV.1 Reression for linear models\n",
    "    - IV.2 Regression for non linear models\n",
    "- X. [References and supplementary material](#X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## III. Maximum Likelihood <a class=\"anchor\" id=\"III\"></a>\n",
    "\n",
    "A common way, in the frequentist sense, to make a point estimation and derive a confidence interval, it through Maximum Likelihood analysis. \n",
    "\n",
    "The first thing to do in that approach is to choose a model $M(\\theta)$ that is supposed to describe the underlying population from which are drawn the data. This allows one to calculate a likelihood as explained below. \n",
    "\n",
    "### III.1 Likelihood:\n",
    "\n",
    "\n",
    "The Likelihood $L$ of a model and of its parameters is defined as $L~=~p(D \\,|\\,M(\\boldsymbol{\\theta}))$. Hence, this is the probability of Data given a model (in fact, given a model and its associated set of parameters). \n",
    "When we talk about the likelihoods of different models we are in general talking about the likelihoods of different sets of parameter values. \n",
    "\n",
    "It is important to note that a likelihood is not strictly speaking a probability as the sum of all the possible outcomes of a model must sum up to one, while the sum of the likelihood of the models (param) needed to explain the data do not have to add up to 1. This can be illustrated using a Gaussian case.   \n",
    "\n",
    "Let's imagine that we have an ensemble of $N$ *independent* random variable {$x_i$} drawn from a normal (i.e. gaussian) distribution of mean $\\mu$ and width $\\sigma$ (i.e. errors on all the measurements $x_i$ are the same (\"homoscedastic\"). \n",
    "\n",
    "We know that the probability of a given measurement $x_k$ is:\n",
    "\n",
    "$$\n",
    "p(x | \\mu, \\sigma ) = \\frac{1}{\\sigma \\sqrt{2\\,\\pi}} \\, \\exp\\left[-0.5 \\left (\\frac{x - \\mu}{\\sigma} \\right)^2\\right] \n",
    "$$\n",
    "\n",
    "If each measurement is independent of the other, the probability of having a given set of measurements will be proportional to the product of the individual probabilities. The likelihood can then be calculated as:\n",
    "\n",
    "$$\n",
    "L \\equiv p({x_i} | \\mu, \\sigma ) = \\prod_{i=1}^{N} \\frac{1}{\\sigma \\sqrt{2\\,\\pi}} \\, \\exp\\left[-0.5 \\left (\\frac{x_i - \\mu}{\\sigma} \\right)^2\\right] = \\frac{1}{\\sigma^n (2\\,\\pi)^{n/2}} \\prod_{i=1}^{N} \\exp \\left (\\frac{(x_i - \\mu)^2}{2\\, \\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "If you measure the likelihood of a data point/measurement $x$, $L$ can be considered as a function of the data. Conversely, you may also consider that you can vary model parameters to maximize the likelihood. In that case we can say that it is a function of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### III.2  Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "The so called *Maximum Lieklihood Approach* used by frequentists (and originally introduced by Fisher -as a third year undegraduate- about 100 years ago), consists in considering the likelihood as a function of the model (parameters) and not as a function of the data. The idea behind the maximization of the likelihood is two fold: i) the probability of any given set of parameters $\\boldsymbol{\\theta}$ is proportional to the probability of observing the data (i.e. the likelihood defined above); ii) the most probable set of values of the parameters (of our model) should also be the one that maximizes the probability of obtaining the data. \n",
    "\n",
    "Seeing the likelihood in the context of the Bayes theorem makes the above argument clearer. The probability to obtain a given set of parameters $\\boldsymbol{\\theta}$ : \n",
    "\n",
    "$$\n",
    "p(M({\\boldsymbol \\theta})|D) = \\frac{p(D \\, | M({\\boldsymbol\\theta})) \\, p(M({\\boldsymbol \\theta}))) }{p(D)}\n",
    "$$\n",
    "\n",
    "[Note that in that expression $p(M({\\bf \\theta})\\,|\\,D)$ is called *posterior probability* (of the model given the data), $p(M({\\boldsymbol \\theta}))$ is the prior on the model parameters, and $p(D) = \\int \\, p(D \\, | \\, M({\\boldsymbol\\theta^\\prime}))\\, p(M({\\boldsymbol \\theta^\\prime})) {\\rm d}{\\boldsymbol \\theta}^\\prime$ is a normalisation factor, also called *evidence*. ]\n",
    "\n",
    "If you assume that you have the same probability for your parameters to occur (i.e. $p(M({\\bf \\theta})$ is uniform), then by maximizing the likelihood, you also maximize the posterior probability of your model (parameters). \n",
    "\n",
    "Because the likelihood can quickly become very small, one generally calculates its logarithm.  The maximum of $\\ln{L}$ (varying the parameters $\\theta$) is obtained by searching the parameters $\\theta$ that yield:\n",
    "\n",
    "$$\n",
    "\\left. \\frac{{\\rm d}ln(L(\\theta_i))}{\\rm{d}\\theta_i}\\right\\vert_{\\hat {\\theta_i}} \\equiv 0\n",
    "$$\n",
    "\n",
    "For our gaussian example, and specialised to the mean $\\mu$, we have:\n",
    "\n",
    "$$\n",
    "\\ln(L(\\mu)) =  -\\frac{n}{2}\\,\\ln(2\\pi) - n\\,\\ln(\\sigma)  - \\sum_{i=1}^N \\frac{(x_i \\,- \\, \\mu)^2}{2\\,\\sigma^2}, \n",
    "$$\n",
    "\n",
    "which is maximum for:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{N} \\, \\sum_{i=1}^{N} x_i\n",
    "$$\n",
    "\n",
    "We can also calculate the derivative w.r.t. to $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial ln(L)}{\\partial \\sigma} = 0 = -\\frac{n}{\\sigma} \\, +\\, \\frac{1}{\\sigma^3} \\, \\sum_i \\, (x_i - \\mu)^2 \n",
    "$$\n",
    "\n",
    "Hence, \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{N} \\, \\sum_i{(x_i-\\mu)^2}\n",
    "$$\n",
    "\n",
    "This tells us that our estimator of the mean, $\\hat{\\mu}$, and of the variance (for a distribution of known mean) $\\hat{\\sigma}^2$ are maximum likelihood estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Exercise: **\n",
    "\n",
    "What is the maximum likelihood estimator for a sample of data points drawn from a gaussian distribution but each point having a different error $\\sigma_i$ (heteroscedastic errors) ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### III.3. Properties of Maximum likelihood estimators\n",
    "\n",
    "MLE are popular in frequentist inference because they gather important properties:\n",
    "\n",
    "1. **consistency**: This means that they converge to the true value when the size of the sample increases. \n",
    "2. **asymptotically normal** estimator: When the size of the sample increases, the distribution of the parameter estimator $\\hat{\\theta}$ converges towards a normal distribution centered on the MLE, with a certain spread. This spread can often be calculated easily to estimate the uncertainty on $\\hat{\\theta}$.\n",
    "3. ** best possible error** given the data. This means that asymptotically, MLE achieve the **theoretical possible minimum of the variance** (Cram√®r-Rao bound). \n",
    "4. **Equivariant** estimator: if $\\hat{\\theta}$ is a MLE estimator of $\\theta$, then $g(\\hat{\\theta})$ is a MLE of $g(\\theta)$\n",
    "\n",
    "**Warning:** these properties rely on some assumptions regarding i) the model from which are drawn the data (i.e. they are all drawn from the same class of pdf -a gaussian in the model above); ii) regularity conditions that allows some derivative to exists (see Chapter 10 of [Lupton 1993](#LUP93) ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.4. Illustration of the MLE approach \n",
    "\n",
    "Let's first look to a simple illustration that consists of a Poisson distribution. \n",
    "First, we define the log-likelihood. Then we make some Poisson sample data, with a rate parameter of 10. This could be, for example, a count rate in a photon detector detecting of the order of 10 photons per second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def poisson_loglike(rate, data):\n",
    "    ## make rate parameter into array of same length as data:\n",
    "    r = np.ones(len(data))*rate\n",
    "    ## now we can compute the log-likelihood:\n",
    "    llike = -np.sum(r) + np.sum(data*np.log(r))-np.sum(scipy.special.gammaln(data + 1))\n",
    "    return llike\n",
    "\n",
    "sample = np.random.poisson(10, size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave it to you to verify that the expression in the definition of the likelihood function is indeed that of the Poisson likelihood for N samples. \n",
    "\n",
    "Now, let's have a look at the shape of the likelihood. We'll use the first 100 events from our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max likelihood log(L)=-24.07, from 10 points, at 9.00\n",
      "Max likelihood log(L)=-251.36, from 100 points, at 10.00\n",
      "Max likelihood log(L)=-2546.28, from 1000 points, at 10.00\n",
      "Max likelihood log(L)=-12881.04, from 5000 points, at 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0xd281908>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd281a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## return likelihood for sample s for a bunch of guesses\n",
    "def guess_like(s):\n",
    "    guesses = np.arange(100)\n",
    "    like_all = [poisson_loglike(g, s) for g in guesses]  \n",
    "    return like_all\n",
    "\n",
    "def plot_like(nsamples, color):\n",
    "    np.random.poisson(10, size=10000)\n",
    "    x = np.arange(100)\n",
    "    llike = np.array(guess_like(sample[:nsamples]))\n",
    "    plt.plot(x, llike, label=\"%i samples\"%nsamples, color=color)\n",
    "    lpos = np.array(guess_like(sample[:nsamples])).argmax()\n",
    "    return  llike, x[lpos]\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "colors = ['blue', 'red', 'pink', 'black']\n",
    "for j, nsamp in enumerate([10, 100, 1000, 5000]):\n",
    "    log_L, x = plot_like(nsamp, colors[j])\n",
    "    print 'Max likelihood log(L)=%.2f, from %.i points, at %.2f' %(log_L.max(), nsamp, x)\n",
    "plt.vlines(10, 0, -100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative is to use minimization algorithm such as e.g. powell function minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 12880.645348\n",
      "         Iterations: 2\n",
      "         Function evaluations: 23\n",
      "The fit-parameter for the Poisson rate parameter: 10.040 \n"
     ]
    }
   ],
   "source": [
    "nsamples = 5000\n",
    "## define the -log-likelihood\n",
    "neg_poisson = lambda r: -poisson_loglike(r, sample[:nsamples])\n",
    "\n",
    "## minimise using Powell's algorithm, starting value for rate parameter is 20\n",
    "result = scipy.optimize.fmin_powell(neg_poisson, 20, full_output=True)\n",
    "\n",
    "print(\"The fit-parameter for the Poisson rate parameter: %.3f \"%result[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV Regression and model fitting\n",
    "\n",
    "Having in hands a set of mutidimensional data, let's say an independent variable $x$, and dependent variable $y$. Then the regression problem of regression consists in finding the expectation value of $y$ given x, i.e. $E(y|x)$ (i.e. this is a conditional expectation value). This is bread and butter of scientific research. If we have a model for the conditional distribution, we can write $y \\, = \\, f(x\\,|\\,{\\boldsymbol{\\theta}})$ where ${{\\boldsymbol{\\theta}}}$ are the parameters of the model. Regression will then consists in finding the parameters $\\boldsymbol{\\theta}$ that yields $E(f(x\\,|\\,\\boldsymbol{\\theta}))$. Note here that $x$, the independant variable, does not have to be a random variable, it could be a deterministic variable, such as a deterministic sampling of a time series. \n",
    "\n",
    "- *Linearity*: Is the model linear *in its parameters*, i.e. $f(x\\,|\\,{\\boldsymbol{\\theta}} = \\sum_{p=1}^{k} \\, \\theta_p g_p(x))$, where $g_p(x)$ can be a non linear function of $x$ BUT does not depend on any of the free parameters. \n",
    "- *Complexity*: A large number of independent variables increases the complexity of the error covariance matrix and of the problem solving. For linear models with small/negligible errors on the independent variable, problem complexity is not a severe issue. \n",
    "- *Error behaviour*: The uncertainties on the dependent and independent variables, and their correlation, generally govern the choice of the regression method. Several situation can occur:\n",
    "    1. Dependent and independent variable have negligible errors\n",
    "    2. Dependent variable $y$ has significant homoscedastic Gaussian error, $x$ has negligible errors. \n",
    "    3. Dependent variable $y$ has significant heteroscedastic Gaussian error, $x$ has negligible errors. \n",
    "    4. Dependent variable $y$ has non Gaussian errors, but their behaviour is known. \n",
    "    5. Dependent variable $y$ has non Gaussian errors, but their behaviour is unknown\n",
    "    6. Errors on the independent variable $x$ are unknown, but the full covariance matrix can be treated as Gaussian. \n",
    "    7. All variables have non gaussian errors. \n",
    "    \n",
    "- Case 1, 2, 3, 4 ->  easily solvable with frequentist or Bayesian techniques.\n",
    "- Case 5 -> 7 are more easily solvable with Bayesian techniques that we will introduce in a future lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.1 Regression for linear models:\n",
    "\n",
    "The problem is the following: we have n data points $y_i$ with associated errors $\\sigma_i$, and a model $f(x_i, \\boldsymbol{\\theta})$ that makes prediction for the values of my data points, i.e. $ f(x_i, \\boldsymbol{\\theta}) = y_{i, \\rm{mod}}$. Then, the standard frequentist approach consists in defining:\n",
    "\n",
    "$$\n",
    "\\chi^2 \\equiv \\sum_{i=1}{n} \\frac{(y_i - y_{i, mod})}{\\sigma_i}\n",
    "$$\n",
    "\n",
    "and finding the parameters $\\boldsymbol{\\theta}$ that minimize that function. \n",
    "\n",
    "When the errors are Gaussian, the likelihood is $L=exp(-\\chi^2/2)$, and hence minimizing the $\\chi^2$ is equivalent to maximizing the likelihood. \n",
    "\n",
    "If the errors are correlated, the covariance matrix, $[C]$ and its inverse, ($[F] \\equiv [C]^{-1}$ , or Fisher matrix) is defined as :\n",
    "\n",
    "$$\n",
    "C_{i,l} \\equiv cov(y_i, y_l). \n",
    "$$\n",
    "\n",
    "I.e., for two random variables $x, y$ we have: \n",
    "\n",
    "$$\n",
    "[F]^{-1} \\, = \\, [C] \\, = \\, \\left[ \\begin{array}{ccc}\n",
    "\\sigma^2_x & \\sigma_{x}\\,\\sigma_y \\\\\n",
    "\\sigma_{x}\\,\\sigma_y & \\sigma^2_y \\\\\n",
    " \\end{array} \\right]   \n",
    "$$\n",
    "\n",
    "Since $[C]$ and $[F]$ are symmetric, the $\\chi^2$ can be written:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i=1}^{n} \\sum_{l=1}^{n}  (y_i - y_{i, mod}) F_{i,l} \\, (y_l - y_{l, mod}). \n",
    "$$\n",
    "\n",
    "You can easily verify that this expressions resumes to the original definition when errors are uncorrelated. \n",
    "\n",
    "Now that we have drawn the general picture, let's study in more details some of the specific classes of problems outlined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### IV.1.1 Fitting a straight line\n",
    "\n",
    "If $x$ is our independent variable, and $y$ the dependent variable, we have:\n",
    "\n",
    "$$\n",
    "y_i = \\theta_0 + \\theta_1 \\, x_i + \\epsilon_i,\n",
    "$$\n",
    "\n",
    "where $\\theta_0$ and $\\theta_1$ are the coefficient we want to estimate (intercept and slope), and $\\epsilon_i$ is an additive noise term (namely the error on $y_i$).\n",
    "\n",
    "*Assumption regarding the noise*: $\\epsilon_i = N(0, \\sigma_i)$ \n",
    "\n",
    "For frequentists, the approach for solving this problem is by maximizing the likelihood, which can be written as: \n",
    "\n",
    "$$\n",
    "L \\, \\equiv \\, p({y_i} | {x_i}, {\\bf{\\theta}} ) =  \\prod_{i=1}^{N} \\frac{1}{\\sigma_i \\sqrt{2\\,\\pi}} \\, \\exp\\left[\\left (\\frac{ -(y_i - (\\theta_0+\\theta_1\\,x_i))^2}{2\\,\\sigma_i^2} \\right)\\right]\n",
    "$$\n",
    "\n",
    "Or, written in terms of log-likelihood:\n",
    "\n",
    "$$\n",
    "\\ln(L) \\equiv \\, ln({\\boldsymbol{\\theta}} | \\{x_i, y_i\\}) \\, \\propto \\sum_{i=1}^{N} \\left (\\frac{ -(y_i - (\\theta_0+\\theta_1\\,x_i))^2}{2\\,\\sigma_i^2} \\right) \n",
    "$$\n",
    "\n",
    "Hence, maximizing the log-likelihood as a function of the model parameters $\\boldsymbol{\\theta}$ in this case, is equivalent to minimizing the sum of the square errors. This is also why it is called \"least square\". \n",
    "\n",
    "**Note**: We will see that Bayesians reach the same conclusion when assuming a flat/uninformative prior on $\\boldsymbol{\\theta}$.  \n",
    "\n",
    "In case of Gaussian homoscedastic uncertainties (we should take the habit to speak of uncertainties rather of errors as the uncertainty on the data points simply results from a random process, hence there is no single value you can access to by making your measurement, while error suggests that you are doing a mistake in making your measurements), you can explicitly derive the values of $\\theta_0, \\theta_1$ and the standard error on the parameters $\\sigma^2_{\\theta_1} , \\sigma^2_{\\theta_2}$. \n",
    "For this purpose, you need to solve two equations with two unknowns:\n",
    "$$\n",
    "\\frac{\\partial \\ln(L)}{\\partial \\theta_1} = 0 \\\\\n",
    "\\frac{\\partial \\ln(L)}{\\partial \\theta_2} = 0\n",
    "$$\n",
    "\n",
    "while the errors on the *parameters* can be derived from the error propagation formula. \n",
    "\n",
    "You end up finding that: \n",
    "\n",
    "$$\n",
    "\\theta_1 = \\frac{\\sum_{i=1}^N x_i y_i - \\bar{x} \\bar{y}} {\\sum_{i=1}^N (x_i - \\bar{x})^2 } \\\\\n",
    "\\theta_0 = \\bar{y} - \\theta_1{\\bar{x}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heteroscedasitc error and matrix formalism\n",
    "\n",
    "For heteroscedastic errors, and even more general regression function, one rather uses a more compact matrix notation.\n",
    "\n",
    "Our problem consists in finding a solution for: \n",
    "$$\n",
    "y_0 = \\theta_0 + \\theta_1 \\, x_0 + \\epsilon_0 \\\\\n",
    "y_1 = \\theta_0 + \\theta_1 \\, x_1 + \\epsilon_1 \\\\\n",
    "... \\\\\n",
    "y_N = \\theta_0 + \\theta_1 \\, x_N + \\epsilon_N\n",
    "$$\n",
    "\n",
    "We can therefore define $M$ (called design matrix) such that $Y = M\\,\\boldsymbol{\\theta} + E$, where $Y$ is a $N$ dimensional vector containing our $y_i$ (i.e. our $N$ points $y_i$):\n",
    "\n",
    "$$\n",
    "Y =  \\left[ \\begin{array}{c}\n",
    "y_0 \\\\ y_1  \\\\ ... \\\\ y_{N-1} \n",
    " \\end{array} \\right]   \n",
    "$$\n",
    "\n",
    "For our straight line regression, $\\boldsymbol{\\theta}$ is a vector containing our 2 parameters:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} =  \\left[ \\begin{array}{c}\n",
    "\\theta_0 \\\\ \\theta_1  \n",
    " \\end{array} \\right] ,\n",
    "$$\n",
    "\n",
    "$M$ is a $2 \\times N$ matrix:\n",
    "\n",
    "$$\n",
    "M =  \\left[ \\begin{array}{cc}\n",
    "1 & x_0 \\\\ 1 & x_1  \\\\ ... \\\\ 1 & x_{N-1} \n",
    " \\end{array} \\right], \n",
    "$$\n",
    "\n",
    "where the constant values in the first columns correspond to the constant value $\\theta_0$ in our regression. \n",
    "\n",
    "And finally, $E$ is \n",
    "$$\n",
    "E =  \\left[ \\begin{array}{c}\n",
    "\\epsilon_0 \\\\ \\epsilon_1  \\\\ ... \\\\ \\epsilon_{N-1}  \n",
    " \\end{array} \\right]   \n",
    "$$\n",
    "\n",
    "The least-square problem consists then in minimizing the sum of the squared residuals $E = M\\,\\boldsymbol{\\theta} - Y$:\n",
    "$$\n",
    "\\sum_i E_i^2 = \\left[ \n",
    "\\epsilon_0 ~ \\epsilon_1 ~ ... ~ \\epsilon_{N-1}  \n",
    "  \\right] \\left[ \\begin{array}{c}\n",
    "\\epsilon_0 \\\\ \\epsilon_1  \\\\ ... \\\\ \\epsilon_{N-1}   \n",
    " \\end{array} \\right] = E^T \\,E\n",
    "$$\n",
    "\n",
    "Hence, this is equivalent to minimizing $E^T \\,E = (M\\boldsymbol{\\theta} - Y)^T \\, (M\\boldsymbol{\\theta} - Y)$\n",
    "\n",
    "The maximum likelihood solution for this regression is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} = (M^T C^{-1} M)^{-1} \\, (M^T C^{-1} Y),\n",
    "$$\n",
    "\n",
    "where $C$ is the $N\\times N$ covariance matrix:\n",
    "\n",
    "$$\n",
    "C =  \\left[ \\begin{array}{cccc}\n",
    "\\sigma_0^2 & 0 & ... & 0 \\\\ \n",
    "0 & \\sigma_1^1 & ... & 0 \\\\ \n",
    "... & ... & ... & ... \\\\\n",
    "0 & 0 & ... & \\sigma_{N-1}^2   \n",
    " \\end{array} \\right] \n",
    "$$\n",
    "\n",
    "This solution minimizes the sum of the square errors, $(Y - \\boldsymbol{\\theta} M)^T C^{-1} (Y-\\boldsymbol{\\theta} M)$.\n",
    "\n",
    "The uncertainties on the regression coefficients $\\boldsymbol{\\theta}$ are then expressed as the symmetric matrix:\n",
    "\n",
    "$$\n",
    "\\Sigma_\\theta = \\left[ \\begin{array}{cc}\n",
    "\\sigma_{\\theta_0}^2 & \\sigma_{\\theta_1 \\, \\theta_1}  \\\\ \n",
    "\\sigma_{\\theta_0 \\theta_1} & \\sigma_{\\theta_1}^2 \\\\ \n",
    " \\end{array} \\right] = [M^T C^{-1} M]^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python implementation:\n",
    "\n",
    "If you simply want to make a linear regression between two data sets $x$ and $y$, you can use in `scipy.stats` the method `linregress` (i.e. `from scipy.stats import linregress`) but this routine does not accept weights (i.e. assumes homoscedastic errors). \n",
    "The alternative is to use `numpy.polyfit(x, y, deg=1, w=1/sigma)`, where $x,y$ are your data, $w$ is the weight associated to the data and `deg=1` is there to fit a model of degree =1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: \n",
    "\n",
    "The file `SNdata.txt` contains distance modulus generated for a simulated sample of supernovae (derived following Sect. 8.1.1 of our [book](#book)). The distance modulus is given by:\n",
    "\n",
    "$$\n",
    "\\mu(z) = -5 \\, \\log10 \\left( (1+z) \\frac{c}{H_0} \\int \\frac{{\\rm d} z}{(\\Omega_m (1+z)^3 + \\Omega_\\Lambda)^{1/2} }  \\right)\n",
    "$$\n",
    "\n",
    "This model is clearly non linear, and the error bars are heteroscdastic Gaussian noise that increases with the supernova redshift. Clearly this won't be well represented with a linear model, but we will keep this example all along (in this lecture and in the upcoming ones) to see how various regression techniques help in fitting those data sets.\n",
    "\n",
    "The file contains 3 columns: 1- The Supernova redshift ; 2- Its distance modulus $\\mu(z)$ (calculated based on some cosmological parameters), and 3- The uncertainty $\\sigma_\\mu$ on the distance modulus.\n",
    "We will now read that file and perform a linear regression on the data. We know that this will not work well, but this does not preclude trying this linear model to see how it performs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted coefficients: slope = 4.623, intercept= 39.687\n",
      "chi^2 = 153.57 , for 98 dof, namely a reduced chi2= 1.57\n",
      "Covariance matrix : \n",
      "[[ 0.13192809 -0.07208123]\n",
      " [-0.07208123  0.05355465]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+QT1quwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe072ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.loadtxt('SNdata.txt')\n",
    "x_data, y_data, sigma = data[:,0], data[:,1], data[:,2]\n",
    "x_data = x_data \n",
    "wght = 1./sigma\n",
    "\n",
    "p_model, cov = np.polyfit(x_data, y_data, deg=1, w=wght, cov=True)\n",
    "xarr = np.linspace(x_data.min(), x_data.max()+0.1, 100)\n",
    "y_model = p_model[1] + p_model[0]*xarr    \n",
    "y_predict = p_model[1] + p_model[0]*x_data   \n",
    "\n",
    "print 'Fitted coefficients: slope = %.3f, intercept= %.3f' %(p_model[0], p_model[1])\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=sigma, ls='', marker='d')\n",
    "plt.plot(xarr, y_model)         # Calculate y for the sorted x array\n",
    "plt.xlabel('redshift (z)')\n",
    "plt.ylabel(r'$\\mu(z)$')\n",
    "\n",
    "chi2 = np.sum(( (y_data-y_predict)/sigma)**2) \n",
    "print 'chi^2 = %.2f , for %i dof, namely a reduced chi2= %.2f' %(chi2, len(x_data)-2, chi2/(len(x_data)-2))\n",
    "print 'Covariance matrix : \\n', cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: (Only FYI) ** Another possibility is to use sklearn which also accepts heteroscedastic errors (but also to distribute bit on multiple processors), is to use the `sklearn` package, and call the routine `LinearRegression` which is part of `sklearn.linear_model`. \n",
    "\n",
    "For making your regression, you do the following:\n",
    "\n",
    "``` python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x, y, weights)  # x need to be of shape [N,1],  while y and weight are of shape [N] \n",
    "\n",
    "y_predict = model.predict(x)  # Predicted values\n",
    "\n",
    "a_mod = model.coef_       # Get the slope\n",
    "b_mod = model.intercept_  # Get the intercept\n",
    "\n",
    "```\n",
    "\n",
    "Unfortunatelly, this implementation of linear regression does not provide the covariance matrix on the fitted parameters. \n",
    "\n",
    "Note that the reason why $x$ has to be of shape [N,1] is that the linear regression as described above can be expanded to multivariate data (i.e. $y_i = \\theta_0+\\theta_1\\,x_{i1} + \\theta_2\\,x_{i2} +  ...+ \\theta_k \\, x_{ik})$), hence to the fit of an hyperplane in $k$ dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted coefficients: slope = 4.536, intercept= 39.744\n",
      "chi^2 = 153.67 , for 98 dof, namely a reduced chi2= 1.57\n"
     ]
    }
   ],
   "source": [
    "# Implementation of the linear fit with sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = np.loadtxt('SNdata.txt')\n",
    "x_data, y_data, sigma = data[:,0], data[:,1], data[:,2]\n",
    "x_data = x_data[:, np.newaxis]    # x should be [N,1] vector\n",
    "wght = 1./sigma\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_data, y_data, wght)\n",
    "y_predict = model.predict(x_data)\n",
    "\n",
    "# Results of the fit\n",
    "slope = model.coef_       # Get the slope\n",
    "intercept = model.intercept_  # Get the intercept\n",
    "print 'Fitted coefficients: slope = %.3f, intercept= %.3f' %(slope, intercept)\n",
    "\n",
    "chi2 = np.sum(( (y_data-y_predict)/sigma)**2) \n",
    "print 'chi^2 = %.2f , for %i dof, namely a reduced chi2= %.2f' %(chi2, len(x_data)-2, chi2/(len(x_data)-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality of the linear regression:\n",
    "\n",
    "We know that if we repeat the observations a large number of times, the $\\chi^2$ should get distributed following a $\\chi^2$ distribution. If $Q = \\sum_{i=1}^{N} z_i^2$ is the sum of the squared residuals, the $\\chi^2$ distribution, with $k = N$ degrees of freedom can be written:      \n",
    "$$\n",
    "p(Q/k) = \\frac{1} {(2\\,\\Gamma(k/2))}  (Q/2)^{k/2-1}  \\exp(-Q/2)\n",
    "$$\n",
    "\n",
    "We know that the expectaiton value in that case is $k$ and the standard deviation $\\sigma = \\sqrt{2k}$. Hence, $E(\\chi^2) = N-nparam$. For the linear fit above, we have 118 dof and hence we expect our $\\chi^2$ to be within some fraction of $\\sigma = \\sqrt{2*118} \\sim 15 $ from 118. \n",
    "\n",
    "In fact, we can even be more quantitative as we can calculate the $P-value$ associated to the $\\chi^2$ we found. \n",
    "Remember, as we have a one-tailed-test, we can simply use `1-cdf(ourchi2)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028075865454627941"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-scipy.stats.chi2.cdf(chi2, df= len(x_data)-2) # Using the cdf (1-p(x < x_i))\n",
    "scipy.stats.chi2.sf(chi2, df= len(x_data)-2)    # Lazy way using the survival function -> p(x > x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: \n",
    "\n",
    "Let's assume the following fake data set:\n",
    "``` python \n",
    "a, b = 0.3, 0\n",
    "xdata = np.arange(0., 6., 0.05)\n",
    "sigma = 0.1  # homoscedastic errors\n",
    "ydata = b + a * xdata + sigma * np.random.randn(len(xdata))\n",
    "```\n",
    "- Fit a straight line to those data\n",
    "- Estimate the quality of the fit. Is it reasonable ? \n",
    "- Re-do the fit using wrong error bars (you can simply give an over/underestimated sigma when calculating the goodness of of fit). Try e.g. overestimate of the error bars by a factor 0.75, 0.9, 1.2, 1.5. Is the new $\\chi^2$ plausible ? What can you say regarding the P-value associated to the $\\chi^2$ found ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.1.2 General least-square fit\n",
    "\n",
    "A generalisation of the case discussed in IV.1.1 is by considering that we have linear combination of any $K$ function of $x$. This could for example be a polynomial of order $K$: \n",
    "\n",
    "$$\n",
    "y_i = \\theta_0 + \\theta_1\\,x_i + \\theta_2\\, x_i^2 + ... + \\theta_K \\, x_i^K\n",
    "$$\n",
    "\n",
    "Either our model is truely polynomial, or is the result of the Taylor expansion of a non linear model. \n",
    "\n",
    "The formula derived for the linear model are still valid but we now need to replace the design matrix M by:\n",
    "$$\n",
    "[M] =  \\left[ \\begin{array}{cccc}\n",
    "1 & x_0 & x_0^2 & ... & x_0^K\\\\ \n",
    "1 & x_1 & x_1^2 & ... & x_1^K \\\\ \n",
    "... \\\\ \n",
    "1 & x_{N-1} & x_{N-1}^2 & ... & x_{N-1}^K\n",
    " \\end{array} \\right], \n",
    "$$\n",
    "\n",
    "Again we can make use of `np.polyfit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted coefficients:  [ -7.10642177  28.05365322 -40.36861874  27.70828185  35.79938077]\n",
      "chi^2 = 96.94 , for 95 dof, namely a reduced chi2= 1.02\n",
      "Covariance matrix : \n",
      "[[  15.48973905  -49.84437726   52.39566332  -20.39654589    2.30053446]\n",
      " [ -49.84437726  163.33570862 -175.50232032   69.97803277   -8.08844771]\n",
      " [  52.39566332 -175.50232032  193.82605035  -79.78423477    9.55098348]\n",
      " [ -20.39654589   69.97803277  -79.78423477   34.2373496    -4.32372705]\n",
      " [   2.30053446   -8.08844771    9.55098348   -4.32372705    0.59923397]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D/X2Tv3JtkbVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using np.polyfit()\n",
    "\n",
    "data = np.loadtxt('SNdata.txt')\n",
    "x_data, y_data, sigma = data[:,0], data[:,1], data[:,2]\n",
    "x_data = x_data \n",
    "wght = 1./sigma\n",
    "deg=4\n",
    "p_model, cov = np.polyfit(x_data, y_data, deg=deg, w=wght, cov=True)\n",
    "\n",
    "# Empty arrays that we will fill with the results of the model\n",
    "xarr = np.linspace(x_data.min(), x_data.max()+0.1, 100)\n",
    "y_model, y_predict = np.zeros(len(xarr)), np.zeros(len(x_data))\n",
    "\n",
    "for i, j in enumerate(range(deg, -1, -1)):   # Model parameters are ordered from highest order to lower one\n",
    "    y_model = y_model + p_model[j] *xarr**i    \n",
    "    y_predict =  y_predict + p_model[j] *x_data**i    \n",
    "\n",
    "print 'Fitted coefficients: ', p_model\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=sigma, ls='', marker='d')\n",
    "plt.plot(xarr, y_model)         \n",
    "plt.xlabel('redshift (z)')\n",
    "plt.ylabel(r'$\\mu(z)$')\n",
    "\n",
    "chi2 = np.sum(( (y_data-y_predict)/sigma)**2) \n",
    "print 'chi^2 = %.2f , for %i dof, namely a reduced chi2= %.2f' %(chi2, len(x_data)-(deg+1), chi2/(len(x_data)-(deg+1)))\n",
    "print 'Covariance matrix : \\n', cov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2 Regression for non linear models:\n",
    "    \n",
    "When the model is **not** anymore linear *in its parameters*, then there is no direct solution through matrix inversion, and it becomes necessary to use purely numerical method. For frequentists, the strategy generally remains to optimize the maximum likelihood estimation, or equivalently minimizing the *weighted sum of the squared residuals* $\\chi^2 = \\sum_{i=1}^{N} \\left( \\frac{y_i - f(x_i)}{\\sigma_i} \\right)^2$. Not that other merit function can be implemented (e.g. maximum entropy). \n",
    "\n",
    "A popular and efficient algorithm to find the parameters that minimize your $\\chi^2$ merit function is the so-called Levenberg-Marquardt algorithm. Conceptually, that method switch between the \"Gradient Descent Method\" (you perturb the parameters by some amount \"h\" in the direction of steepest descent in your $\\chi^2$ function), and the \"Gauss-Newton Method\" that assumes that locally your function is quadratic in the parameters to determine \"h\", through a \"lagrange parameter\" lambda that is modified depending of the observed change in merit function. \n",
    "\n",
    "In python, you can use the `curve_fit()` function from the `scipy.optimize` to apply levenberg Marquardt to the fit of your function. \n",
    "\n",
    "The `curve_fit()` function works like this:\n",
    "``` python\n",
    "# first create a function that defines your model\n",
    "# It must take the independent variable as the first argument and the parameters to fit as separate remaining arguments.\n",
    "def func(x, p1, p2, p3):\n",
    "y = f(x, p1, p2, p3)  # replace f(x, p1, p2, p3) by a function of vector x with parameters p1, p2, p3\n",
    "    return y\n",
    "# Second we call curve_fit(), first three arguments being func, xdata, ydata. Next two are optional initial guess and errors on y. \n",
    "pfit, pcov = scipy.optimize.curve_fit(func, xdata, ydata, p0=x0, sigma=sigma) \n",
    "# there is the possibility to constrain the parameters to certain ranges using method = 'trf'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## X. References and supplementary material: <a class=\"anchor\" id=\"X\"></a>\n",
    "\n",
    "**Chapter 4 ** (4.5, 4.7), **Chapter 8 ** of the book <a class=\"anchor\" id=\"book\"></a> *Statistics, data mining and Machine learning in astronomy* by Z. Ivezic et al. in Princeton Series in Modern Astronomy. \n",
    "\n",
    "* $\\chi^2$ and linear fits, Andy Gould, https://arxiv.org/abs/astro-ph/0310577\n",
    "\n",
    "* All of statistics: a concise course in statistical inference*, Wasserman 2004  <a class=\"anchor\" id=\"WAS04\"></a>(see also errata in http://www.stat.cmu.edu/~larry/all-of-statistics/): **Chapter 8, 9 **\n",
    "\n",
    "* *Statistics in theory and Practice*, Lupton 1993 <a class=\"anchor\" id=\"LUP93\"></a>: **Chapter 6, 7, 8, 9 **\n",
    "\n",
    "* Numerical recipes: Chapter 14 and 15\n",
    "\n",
    "Other useful references to know more about the topics covered in this class: \n",
    "\n",
    "- Sklearn help: http://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "- Contribution of Fisher to MLE: J.A. Aldrich R. A. Fisher and the Making of Maximum Likelihood 1912‚Äì 1922 About Fisher's invention of Maximum Likelihood: Statistical science, 1997, 12, 3, 162 https://projecteuclid.org/download/pdf_1/euclid.ss/1030037906 \n",
    "\n",
    "- More tests and hypothesis testing: https://onlinecourses.science.psu.edu/stat414/node/290 ; https://onlinecourses.science.psu.edu/stat200/node/51 \n",
    "\n",
    "- Bootstrap: A. C. Davison, D. V. Hinkley and G. A. Young, Statistical science, 2003, 18, 2, 141: Recent Developments in Bootstrap Methodology https://projecteuclid.org/download/pdf_1/euclid.ss/1063994969\n",
    "\n",
    "- Bootstrap: University of Kentucky: STAT 621 http://web.as.uky.edu/statistics/users/pbreheny/621/F12/ by Patrick Breheny \n",
    "    \n",
    "- Fisher matrices and confidence ellipses: Coe 2009 https://arxiv.org/abs/0906.4123    \n",
    "\n",
    "- Online Statistics Education: A Multimedia Course of Study (http://onlinestatbook.com/). Project Leader: David M. Lane, Rice University.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
